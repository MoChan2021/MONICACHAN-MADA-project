---
title: "Random Forest"
author: "MYC"
date: "11/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Helper packages
library(tidyverse) # for data manipulation & graphics suite
library(here)      # for easy specification of relative locations
library(tidymodels)# for modeling process suite  
library(caret)     # for resampling and model training
library(rpart)
library(rpart.plot)
library(glmnet)
```
Path to data
```{r Data}
#note the use of the here() package and not absolute paths
data_location <- here::here("data","processed_data","P2-20211029.rds")
#read and load data. 
```
Import P2 data
```{r}
P2<- readRDS(data_location)
```

Add to the data -- Fix so we add a catagorical aspect to Ct values- simplicity make Detected/Yes (< 37.9) and Undetected/No (>38)

Bonus- try to figure out how to change into 3 levels?
```{r}
P2.Plus.Cat<-
  P2%>%
  mutate(
# if greater than ct 38, this is a negative detection, thus less 38 is a positive in detection
    Ct.Cat = ifelse(Ct >=38,"No","Yes"), 
# There are some NAs, they are undetectable, change only in the Ct.Cat to No as a factor    
    Ct.Cat=ifelse(is.na(Ct.Cat), "No",Ct.Cat),
# These are factors so mutate the chr to fctrs
    Ct.Cat=factor(Ct.Cat)
    )%>%
#Remove/adjust so there are no character based factors
    select(RH,TEMP, Method, Tool, Input, Detector, Ct, Ct.Cat)%>%
  na.omit()

summary(P2.Plus.Cat)  
```

Set Seed for reproducibility
```{r}
# Fix the random numbers by setting the seed 
set.seed(123)
# This enables the analysis to be reproducible when random numbers are used
```

1. Data splitting into training and testing sets (Random sampling)
  1. Training
  2. Testing
  
```{r}
# Put 3/4 of the data into the training set; this leaves 1/4 of the data to be used to test 
data_split <- initial_split(P2.Plus.Cat, prop = 3/4)

## Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
```

```{r}
#View the train and test data
glimpse(train_data)
glimpse(test_data)
```

2. Creating Models

#  Ct value or Detection as function of method and inital dilution 
Detection ~ Model + Dilution

# Ct value or detection for all precitcors (short hand for all predictors)
Detection~., data=P2.Plus.Cat

2.1. Many engines Examples
```{r}
# fit linear model
lm_lm    <- lm(Ct ~ ., data = P2.Plus.Cat)
# fit general linear model
lm_glm   <- glm(Ct ~ ., data = P2.Plus.Cat, 
                family = gaussian)
#########
#<atempt to use later>
# meta engine (aggregator) method=<method name>; see parsnips
#lm_caret <- train(Ct ~ ., data = P2.Plus.Cat, 
#                 method = "glm")
```

2.4. Resampling - CV
```{r }
# create CV object from training data
cv_data <- rsample::vfold_cv(train_data, v = 5, repeats = 5, strata = 'Ct')

print(cv_data)

############## below are similar functions but need to try

#apply CV in ML algorithm to process the ML model to each resample
vfold_cv(P2.Plus.Cat, v=5)

```
Preprocessing
Using parsnims to create a recipe for fitting the model
No standardization
adding dummy variables are added
```{r}
fit_recipe <- 
# set a recipe
  recipe(Ct ~ ., data = P2.Plus.Cat) %>%
# code all categorical variables as dummy variables
  step_dummy(all_nominal()) 

print(fit_recipe)
```
Null Model
Ct is a continuations outcome of numbers-- need to use RMSE as performance metric.
```{r}
RMSE_null_train <- sqrt(sum( (train_data$Ct - mean(train_data$Ct))^2 )/nrow(train_data))

RMSE_null_test <- sqrt(sum( (test_data$Ct - mean(test_data$Ct))^2 )/nrow(test_data))

print(RMSE_null_train)

#predict(lm_lm, train_data=Ct)
```

```{r}
rf_model <- rand_forest() %>%
  set_args(mtry = tune(),     
    trees = tune(),
    min_n = tune()
  ) %>%
  # select the engine/package that underlies the model
  set_engine("ranger",
             num.threads = 18, #for some reason for RF, we need to set this in the engine too
             importance = "permutation") %>%
  # choose either the continuous regression or binary classification mode
  set_mode("regression")   
```

```{r}
#workflow
rf_wf <- workflow() %>%
  add_model(rf_model) %>% 
  add_recipe(fit_recipe)
```
Model tuning with a grid.

```{r}
#tuning grid
rf_grid  <- expand.grid(mtry = c(3, 4, 5, 6), min_n = c(40,50,60), trees = c(500,1000)  )

# tune the model, optimizing RMSE
rf_tune_res <- rf_wf %>%
  tune_grid(
            resamples = cv_data, #CV object
            grid = rf_grid, # grid of values to try
            metrics = metric_set(rmse) 
  )
```
Plot the performance of the grid tune results.
```{r}
#see a plot of performance for different tuning parameters
rf_tune_res %>% autoplot()
```


```{r}
# get the tuned model that performs best 
best_rf <- rf_tune_res %>%  select_best(metric = "rmse")

# finalize workflow with best model
best_rf_wf <- rf_wf %>% finalize_workflow(best_rf)

# fitting best performing model
best_rf_fit <- best_rf_wf %>% 
  fit(data = train_data)
rf_pred <- predict(best_rf_fit, train_data)
```
Use vip to learn about variable importance in the modeling
```{r}
#pull out the fit object
x <- best_rf_fit$fit$fit$fit
#plot variable importance
P2RFBestFit<-vip::vip(x, geom="point",aesthetics = list(color = "blue", shape = 17, size = 4))

print(P2RFBestFit)
```
Meaning that the point of Tool B is the most important/predictive variable for Ct outcome, makes sense as the top 3 are tool related and all have different "concentrations".
Also not pressurizing that Dilution and Input are important.
Method has virtually 0 importance in the Ct value during the modeling. 
```{r warning=FALSE}
#save figure
figure_file = here("results","P2-RF-BestFit.png")
ggsave(filename = figure_file, plot=P2RFBestFit) 
```

```{r}
#predicted versus observed
plot(rf_pred$.pred,train_data$Ct )
abline(a=0,b=1, col = 'red') #45 degree line, along which the results should fall
```
```{r}
#residuals
plot(rf_pred$.pred-train_data$Ct)
abline(a=0,b=0, col = 'red') #straight line, along which the results should fall
```
```{r}
rf_perfomance <- rf_tune_res %>% show_best(n = 5)
print(rf_perfomance)
```

